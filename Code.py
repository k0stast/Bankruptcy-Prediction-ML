# -*- coding: utf-8 -*-
"""Εργασία 2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DB8i3pAknSV3-FjIaMyK6D2_OsQbGKpE
"""

# Import the necessary module to access Google Drive
from google.colab import drive

# Mount Google Drive to the Colab environment at the specified path
drive.mount('/content/drive')

# Import the pandas library for data manipulation
import pandas as pd
# Step 1
file_path = '/content/drive/MyDrive/Dataset2Use_Assignment2.xlsx'  # Define the path to the Excel file on Google Drive
df = pd.read_excel(file_path)  # Load the Excel file into a DataFrame
df.head() # Display the first 5 rows of the DataFrame

#Step 2
import matplotlib.pyplot as plt

# Rename columns for easier access in code
df = df.rename(columns={
    'ΕΝΔΕΙΞΗ ΑΣΥΝΕΠΕΙΑΣ (=2) (ν+1)': 'target',  # Binary target: 1 = healthy, 2 = bankrupt
    'ΕΤΟΣ': 'year'  # Year column
})

# Group data by year and target, then count occurrences
counts = df.groupby(['year', 'target']).size().unstack(fill_value=0)

# Create a stacked bar chart to visualize the number of companies per category over time
counts.plot(kind='bar', stacked=True, figsize=(10,6))
plt.title("Figure 1: Αριθμός υγιών και πτωχευμένων επιχειρήσεων ανά έτος")
plt.xlabel("Έτος")
plt.ylabel("Αριθμός επιχειρήσεων")
plt.legend(["Υγιείς (1)", "Πτωχευμένες (2)"])
plt.tight_layout()
plt.show()

# Step 2
# Select the first 8 columns which represent the numeric financial indicators
indicator_cols = df.columns[:8]  # First 8 columns are the company performance indicators

# Filter the dataset into two groups: healthy and bankrupt companies
healthy = df[df['target'] == 1]
bankrupt = df[df['target'] == 2]

# Calculate the min, max, and mean values of each indicator for both groups
healthy_stats = healthy[indicator_cols].agg(['min', 'max', 'mean'])
bankrupt_stats = bankrupt[indicator_cols].agg(['min', 'max', 'mean'])

# Create a side-by-side bar plot to visualize the statistics for both groups
fig, axes = plt.subplots(1, 2, figsize=(16, 6), sharey=True)

# Plot statistics for healthy companies (logarithmic y-axis for better readability)
healthy_stats.T.plot(kind='bar', ax=axes[0], logy=True)
axes[0].set_title("Υγιείς Επιχειρήσεις (Log Scale)")
axes[0].set_xticklabels(indicator_cols, rotation=90)

# Plot statistics for bankrupt companies
bankrupt_stats.T.plot(kind='bar', ax=axes[1], logy=True, color=['r', 'orange', 'green'])
axes[1].set_title("Πτωχευμένες Επιχειρήσεις (Log Scale)")
axes[1].set_xticklabels(indicator_cols, rotation=90)
axes[1].legend(loc='upper left', bbox_to_anchor=(1.02, 1))

# Add a common title and adjust layout
fig.suptitle("Figure 2: Min, Max, Mean ανά δείκτη (Log scale)", fontsize=14, y=1.02)
plt.tight_layout()
fig.subplots_adjust(top=0.85)
plt.show()

# Step 3
# Count the number of NaN values in each column
nan_counts = df.isnull().sum()

# Filter to show only the columns that contain at least one NaN value
nan_columns = nan_counts[nan_counts > 0]

# Print appropriate message depending on whether missing values were found
if nan_columns.empty:
    print("Δεν υπάρχουν ελλιπείς εγγραφές (NaN) στο dataset.")
else:
    print("Βρέθηκαν ελλιπείς τιμές στις παρακάτω στήλες:")
    print(nan_columns)



# Step 4
# Import scaler from scikit-learn
from sklearn.preprocessing import MinMaxScaler

# Select the columns to be normalized (first 8 indicators)
numeric_cols = df.columns[:8].tolist()

# Apply Min-Max scaling to bring values into the [0, 1] range
scaler = MinMaxScaler()
df[numeric_cols] = scaler.fit_transform(df[numeric_cols])

# Display the first few rows of the DataFrame to verify normalization
df.head()

# Steps 5–10
#Model training, evaluation, and results export
from sklearn.model_selection import StratifiedKFold
from sklearn.utils import resample
from sklearn.metrics import (
    confusion_matrix, accuracy_score, precision_score,
    recall_score, f1_score, roc_auc_score
)
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np

# Prepare features and target variable
X = df.drop(columns=['target', 'year'])  # Drop target and year from features
y = df['target']  # Target variable (1 = healthy, 2 = bankrupt)

# Define classification models to be used
models = {
    "LDA": LinearDiscriminantAnalysis(),
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "Decision Tree": DecisionTreeClassifier(),
    "Random Forest": RandomForestClassifier(),
    "k-NN": KNeighborsClassifier(),
    "Naive Bayes": GaussianNB(),
    "SVM": SVC(probability=True),
    "MLP (Neural Network)": MLPClassifier(max_iter=500)
}

# Store evaluation results for all models and folds
results = []

# Use StratifiedKFold to ensure proportional class distribution
skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)

fold_number = 1
for train_index, test_index in skf.split(X, y):
    print(f"\n{'='*60}\nFold {fold_number}")

     # Step 6: Train-test split for the current fold
    X_train_full, X_test = X.iloc[train_index], X.iloc[test_index]
    y_train_full, y_test = y.iloc[train_index], y.iloc[test_index]

    print(f"Train set: Υγιείς = {np.sum(y_train_full == 1)}, Πτωχευμένες = {np.sum(y_train_full == 2)}")
    print(f"Test set:  Υγιείς = {np.sum(y_test == 1)}, Πτωχευμένες = {np.sum(y_test == 2)}")

    # Step 7: Balance the training set to 3:1 ratio
    train_data = X_train_full.copy()
    train_data['target'] = y_train_full
    healthy = train_data[train_data['target'] == 1]
    bankrupt = train_data[train_data['target'] == 2]

    if len(healthy) > 3 * len(bankrupt):
        healthy_sampled = resample(healthy, replace=False, n_samples=3 * len(bankrupt), random_state=fold_number)
        balanced_train = pd.concat([healthy_sampled, bankrupt])
    else:
        balanced_train = train_data.copy()

    balanced_train = balanced_train.sample(frac=1, random_state=fold_number).reset_index(drop=True)
    final_X_train = balanced_train.drop(columns=['target'])
    final_y_train = balanced_train['target']

    print(f"Balanced Train set: Υγιείς = {sum(final_y_train == 1)}, Πτωχευμένες = {sum(final_y_train == 2)}")

    # Step 8–9: Train and evaluate all models
    for name, model in models.items():
        model.fit(final_X_train, final_y_train)

        # Evaluate on both train and test sets
        for dataset_type, X_eval, y_eval in [("train", final_X_train, final_y_train), ("test", X_test, y_test)]:
            y_pred = model.predict(X_eval)
            # Try to compute ROC-AUC if predict_proba is available
            try:
                y_prob = model.predict_proba(X_eval)[:, 1] # Probabilities for class "2"
                auc = roc_auc_score((y_eval == 2).astype(int), y_prob)
            except:
                auc = 0.0
            # Compute confusion matrix
            cm = confusion_matrix(y_eval, y_pred, labels=[1, 2])
            plt.figure(figsize=(4, 3))
            sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
            plt.title(f"{name} - Fold {fold_number} - {dataset_type}")
            plt.xlabel("Predicted")
            plt.ylabel("Actual")
            plt.show()

            # Compute performance metrics
            acc = accuracy_score(y_eval, y_pred)
            prec = precision_score(y_eval, y_pred, pos_label=2)
            rec = recall_score(y_eval, y_pred, pos_label=2)
            f1 = f1_score(y_eval, y_pred, pos_label=2)

            # Extract TP, TN, FP, FN from confusion matrix
            cm_binary = confusion_matrix(y_eval, y_pred, labels=[1, 2])
            tn = cm_binary[0, 0]
            fp = cm_binary[0, 1]
            fn = cm_binary[1, 0]
            tp = cm_binary[1, 1]


            print(f"{name} | Fold {fold_number} | {dataset_type}")
            print(f"Accuracy: {acc:.2f} | Precision: {prec:.2f} | Recall: {rec:.2f} | F1: {f1:.2f} | AUC: {auc:.2f}")

            # Store results
            results.append({
                "Classifier Name": name,
                "Training or test set": dataset_type,
                "Balanced or unbalanced train set": "balanced",
                "Number of training samples": len(final_X_train),
                "Number of non-healthy companies in training sample": sum(final_y_train == 2),
                "TP": tp,
                "TN": tn,
                "FP": fp,
                "FN": fn,
                "ROC-AUC": round(auc, 2)
            })

    fold_number += 1

# Step 10: Export all results to a CSV file
results_df = pd.DataFrame(results)
results_df.to_csv("balancedDataOutcomes.csv", index=False)

from google.colab import files
files.download('balancedDataOutcomes.csv')

file_path2 = '/content/drive/MyDrive/balancedDataOutcomes.csv'
df2 = pd.read_csv(file_path2)
df2.head()
df2.to_excel("balancedDataOutcomes.xlsx", index=False)
files.download("balancedDataOutcomes.xlsx")